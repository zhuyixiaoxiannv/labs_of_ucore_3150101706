这个lab5比起之前要更加复杂一些。lab4的是内核线程，所以很多事情不管也没关系。但是这是两个虚拟空间的，用户线程和内核线程的虚拟空间不同，所以感觉涉及到很多内容。

#### system_call
先说这个子系统是因为内容并不多，就之前lab1里面，首先是更改中断选择子，主要是特权级。增加了中断号为T_SYSCALL情况下的处理，然后呢，再调用syscall里面的函数入口，根据eax里面的数值，进行调用。

然后进行了很多乱七八糟的处理，这里面的系统调用就多了，有的关于进程的，比如kill，fork巴拉巴拉，也有打印字符串什么的都有。

另注，T_SYSCALL在<unistd.h>中定义（找了我半天）

还有就是，每过100个时钟中断就设置一次需要schedule。看了时钟中断的代码，也就是一秒钟就切换一次进程。

但我，觉得这还得每次程序计数器加一。

#### 时钟中断
（本来这个应该写在lab1里面的，这是硬件相关）
好吧看不懂。

8253可用作定时器和计数器，有三个计数器0、1、2，7根数据线D0-D7，两根地址译码线A1-A0，每个计数器有6种不同的工作方式。
参考
https://www.jianshu.com/p/55fc16925a4a

虽然这里面把DX设为端口，并不是经常做的事情。
另外，六种工作方式可以参考百科。

#### 内存分配

首先，看了之后，反应过来，这是虚拟内存分配，不是物理内存分配。（物理内存分配在这边其实是不可见的一件事情。就是，我也不知道它每个虚拟页被分配到哪个页框里面去。）所以不用考虑会覆盖掉最底下的地址空间。

而物理内存的分配其实没啥要紧的。

我真的感觉内存分配这件事，确实是头等要紧的麻烦事情。感觉主要就是三个部分，一个是内存如何给新的进程分配，第二个就是内核相关的数据结构的改变，第三个就是进程上下文的更改

我这边记录一下他新创建一个进程的内核需要考虑的事情。

然后还记得那个内存自映射吗，那个意味着需要4mb的空间，是最顶部的那个FAC00000开始的。



# 实验执行流程概述（就直接用原来的名字了）

```
另一方面，不同的进程有各自的页表，所以即使不同进程的用户态虚拟地址相同，但由于页表把虚拟页映射到了不同的物理页帧，所以不同进程的虚拟内存空间是被隔离开的，相互之间无法直接访问。在用户态内存空间和内核态内核空间之间需要拷贝数据，让CPU处在内核态才能完成对用户空间的读或写，为此需要设计专门的拷贝函数（copy_from_user和copy_to_user）完成。

bool
copy_from_user(struct mm_struct *mm, void *dst, const void *src, size_t len, bool writable) {
    if (!user_mem_check(mm, (uintptr_t)src, len, writable)) {
        return 0;
    }
    memcpy(dst, src, len);
    return 1;
}

bool
copy_to_user(struct mm_struct *mm, void *dst, const void *src, size_t len) {
    if (!user_mem_check(mm, (uintptr_t)dst, len, 1)) {
        return 0;
    }
    memcpy(dst, src, len);
    return 1;
}
```

贴上面的代码的意思，很简单，emmm就是，这里面，两个进程间的通信和信息的传输，把他弄到内核空间，再弄到另一个进程的空间去。

```
在进程管理方面，主要涉及到的是进程控制块中与内存管理相关的部分，包括建立进程的页表和维护进程可访问空间（可能还没有建立虚实映射关系）的信息；加载一个ELF格式的程序到进程控制块管理的内存中的方法；在进程复制（fork）过程中，把父进程的内存空间拷贝到子进程内存空间的技术。另外一部分与用户态进程生命周期管理相关，包括让进程放弃CPU而睡眠等待某事件；让父进程等待子进程结束；一个进程杀死另一个进程；给进程发消息；建立进程的血缘关系链表。
```
这里面主要是说了几件事，
1. 包括建立进程的页表和维护进程可访问空间（可能还没有建立虚实映射关系）的信息，就是前面讲到的那个mm结构的作用——请充分理解
2. 加载一个ELF格式的程序。

```
当实现了上述内存管理和进程管理的需求后，接下来ucore的用户进程管理工作就比较简单了。首先，“硬”构造出第一个进程（lab4中已有描述），它是后续所有进程的祖先；然后，在proc_init函数中，通过alloc把当前ucore的执行环境转变成idle内核线程的执行现场；然后调用kernl_thread来创建第二个内核线程init_main，而init_main内核线程有创建了user_main内核线程.。到此，内核线程创建完毕，应该开始用户进程的创建过程，这第一步实际上是通过user_main函数调用kernel_tread创建子进程，通过kernel_execve调用来把某一具体程序的执行内容放入内存。
```



#### 本实验中，应用程序的加载

首先得看的是，这个应用程序是怎么弄得（在提供了一堆system的中断处理程序之后）

```
user/libs/initcode.S：所有应用程序的起始用户态执行地址“_start”，调整了EBP和ESP后，调用umain函数。
user/libs/umain.c：实现了umain函数，这是所有应用程序执行的第一个C函数，它将调用应用程序的main函数，并在main函数结束后调用exit函数，而exit函数最终将调用sys_exit系统调用，让操作系统回收进程资源。
```

好吧，也就是调用main，之前给一堆测试，之后给一个系统exit调用就完了。

重要的是链接器和加载器怎么做的，链接器：

```
在make的最后一步执行了一个ld命令，把hello应用程序的执行码obj/__user_hello.out连接在了ucore kernel的末尾。且ld命令会在kernel中会把__user_hello.out的位置和大小记录在全局变量_binary_obj___user_hello_out_start和_binary_obj___user_hello_out_size中，这样这个hello用户程序就能够和ucore内核一起被 bootloader 加载到内存里中，并且通过这两个全局变量定位hello用户程序执行码的起始位置和大小。而到了与文件系统相关的实验后，ucore会提供一个简单的文件系统，那时所有的用户程序就都不再用这种方法进行加载了，而可以用大家熟悉的文件方式进行加载了。
```

简单粗暴干的漂亮。

然后呢，加载器做的事情就是，用了好几个KERNEL_EXECVE的宏定义？？？其中用到了上面讲的两个全局变量。然后调用kernel_execve。然后，这个kernel_execve调用了系统的syscall里面的do_exec，就跑起来了。

而这个宏的调用则是如前面所说的，init_main内核线程有创建了user_main内核线程，在user_main这个thread里面被调用

#### 



#### load_icode

```
load_icode函数的主要工作就是给用户进程建立一个能够让用户进程正常运行的用户环境。此函数有一百多行，完成了如下重要工作：

调用mm_create函数来申请进程的内存管理数据结构mm所需内存空间，并对mm进行初始化；

调用setup_pgdir来申请一个页目录表所需的一个页大小的内存空间，并把描述ucore内核虚空间映射的内核页表（boot_pgdir所指）的内容拷贝到此新目录表中，最后让mm->pgdir指向此页目录表，这就是进程新的页目录表了，且能够正确映射内核虚空间；

根据应用程序执行码的起始位置来解析此ELF格式的执行程序，并调用mm_map函数根据ELF格式的执行程序说明的各个段（代码段、数据段、BSS段等）的起始位置和大小建立对应的vma结构，并把vma插入到mm结构中，从而表明了用户进程的合法用户态虚拟地址空间；

调用根据执行程序各个段的大小分配物理内存空间，并根据执行程序各个段的起始位置确定虚拟地址，并在页表中建立好物理地址和虚拟地址的映射关系，然后把执行程序各个段的内容拷贝到相应的内核虚拟地址中，至此应用程序执行码和数据已经根据编译时设定地址放置到虚拟内存中了；

需要给用户进程设置用户栈，为此调用mm_mmap函数建立用户栈的vma结构，明确用户栈的位置在用户虚空间的顶端，大小为256个页，即1MB，并分配一定数量的物理内存且建立好栈的虚地址<-->物理地址映射关系；

至此,进程内的内存管理vma和mm数据结构已经建立完成，于是把mm->pgdir赋值到cr3寄存器中，即更新了用户进程的虚拟内存空间，此时的initproc已经被hello的代码和数据覆盖，成为了第一个用户进程，但此时这个用户进程的执行现场还没建立好；

先清空进程的中断帧，再重新设置进程的中断帧，使得在执行中断返回指令“iret”后，能够让CPU转到用户态特权级，并回到用户态内存空间，使用用户态的代码段、数据段和堆栈，且能够跳转到用户进程的第一条指令执行，并确保在用户态能够响应中断；

至此，用户进程的用户环境已经搭建完毕。此时initproc将按产生系统调用的函数调用路径原路返回，执行中断返回指令“iret”（位于trapentry.S的最后一句）后，将切换到用户进程hello的第一条语句位置_start处（位于user/libs/initcode.S的第三句）开始执行。
```

emmm,意思就是，每个进程都会单独的有个虚拟空间，这是由mm来决定的，但是并不意味着内核的东西没了，每个进程创建的时候都将内核的页目录表都复制过去，所以每个进程都能够使用内核的代码（但是要考虑特权级等问题，syscall的特权级是user的特权级，从而可以进行系统调用。emmm，反正我现在的概念就是，内核的代码其实是共享的就酱紫。

反正这个新的虚拟空间中，有内核的代码（在末尾），然后对于可用的内存进行vma的创建

至于跳转执行，就是把iret的返回码更改了，就好了。

另外就是加载用户代码。

与之对应的是进程销毁的过程。

这里面对于mm的处理，我觉得值得一提——因为这玩意决定了用户进程的虚拟内存空间。

```
首先为加载新的执行码做好用户态内存空间清空准备。如果mm不为NULL，则设置页表为内核空间页表，且进一步判断mm的引用计数减1后是否为0，如果为0，则表明没有进程再需要此进程所占用的内存空间，为此将根据mm中的记录，释放进程所占用户空间内存和进程页表本身所占空间。最后把当前进程的mm内存管理指针为空。由于此处的initproc是内核线程，所以mm为NULL，整个处理都不会做。
```

主要是在do_execve里面，需要清空mm销毁一堆东西。原因是，他用了fork，fork之后将进程的虚拟空间这些复制给了新的，但是新的要么自己新创建，总不能用原来的吧。所以要清空。

（为什么lab5要这么多地方要填代码呀）

#### 总结一下下

大概就是前面执行流程里面的步骤（这指的是，这个lab里面是怎么生成第一个程序的），还有就是fork，execute，wait，kill，exit等等几个系统调用的实现，最后就是trap文件里面的改变。

fork只是将这堆东西给复制一波，但是execute则是更改了里面的内容（考虑到后面有了文件系统之后呢，这种加载方式肯定是废弃的所以也不用特别关注这些东西。

所做的事情，我也都有摘录，最重要的mm结构体，里面涉及到了虚拟空间的更改，然后其他的主要是上下文吧——看是看不完的，大概框架懂了就完了，能怎么办（摊手，能让他跑起来就不容易了）